,agent_memory,replay_buffer_size,state_dimension,action_dimension,episode_reward,episode_steps,episode_duration,episode_exploration_rate,episode_states_entropy,cpu_memory,gpu_memory
0,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
1,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
2,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
3,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
4,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
5,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
6,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
7,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
8,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
9,,10000,"(210, 160, 3)",6,-20.0,838,0.3827519416809082,0.010080963560932535,0,474279936,0
