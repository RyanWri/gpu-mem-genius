agent:
  gamma: 0.99                # Discount factor
  epsilon: 1.0               # Initial exploration probability
  epsilon_decay: 0.9995      # Decay rate of epsilon (matches paper)
  epsilon_min: 0.1           # Minimum epsilon for exploration
  learning_rate: 0.00025     # Learning rate for the optimizer (matches paper)
  target_update_frequency: 1000  # Update target network every 10,00 steps

replay_buffer:
  buffer_size: 100000       # Increased to match original DQN
  batch_size: 32             # Matches paper

environment:
  game_name: "ALE/Freeway-v5"   # Name of the Atari game
  render_mode: "rgb_array"   # Render mode (e.g., "human", "rgb_array", etc')
  obs_type: "grayscale"      # Observation type (e.g., "grayscale", "rgb", etc')
  max_steps: 10000           # Maximum steps per episode
  episodes: 1200            # Increased episodes to match original training time
  batch_size: 32             # Matches paper
  target_update_frequency: 1000  # Update target network every 10,000 steps

checkpoints:
  frequency: 600
  data: 200

save_options: 
  folder: "/home/ran/datasets/atari-mem/Freeway-v5"
  format: "csv"