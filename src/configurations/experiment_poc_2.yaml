agent:
  gamma: 0.99                # Discount factor
  epsilon: 1.0               # Initial exploration probability
  epsilon_decay: 0.9995      # Decay rate of epsilon (matches paper)
  epsilon_min: 0.1           # Minimum epsilon for exploration
  learning_rate: 0.00025     # Learning rate for the optimizer (matches paper)
  target_update_frequency: 10000  # Update target network every 10,000 steps

replay_buffer:
  buffer_size: 1000000       # Increased to match original DQN
  batch_size: 32             # Matches paper

environment:
  game_name: "ALE/Pong-v5"   # Name of the Atari game
  render_mode: "rgb_array"   # Render mode (e.g., "human", "rgb_array", etc')
  obs_type: "grayscale"      # Observation type (e.g., "grayscale", "rgb", etc')
  max_steps: 10000           # Maximum steps per episode
  episodes: 50000            # Increased episodes to match original training time
  batch_size: 32             # Matches paper
  target_update_frequency: 10000  # Update target network every 10,000 steps
  save_options: 
    folder: "/home/ran/datasets/atari-mem"
    format: "csv"
